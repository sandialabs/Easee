"""
Jeremy D. Wendt
jdwendt@sandia.gov
Arvind Prasadan
aprasad@sandia.gov

    MergeGraphs.py
    
    This code implements Algorithm 2 described in Wendt, Field, Phillips, Prasadan, Wilson, 
    Soundarajan, and Bhowmick, "Partitioning Communication Streams into Graph Snapshots",
    2020.  This code contains some extra analyses for creating plots for the paper beyond
    those described in the simplified Algorithm 2 in the paper.

# Usage: 
    python MergeGraphs.py "Input Filename" "Number of input files" "Output Filename Base"

# Inputs:
    - Input filename (Base; edge file) - The basename for the graph files output by 
    CreateGraphs.py.  If inputs do not have the expected header-line (node_a,node_b,
    first_time,last_time,num_times), this will fail.
    - Output filename (Base) - Extensions added for an output file with cosine, Jaccard,
    and weighted Jaccard similarities included for all analyzed graph similarities as 
    follows:
    id_x,id_y,nodes_jaccard,edges_jaccard,nodes_cosine,edges_cosine,nodes_wjaccard,edges_wjaccard

# Assumptions:
    - Input Files are created with CreateGraphs.py (formatting)
"""


import sys
import math
import numpy as np
from copy import deepcopy

def normalize(v):
    """
        normalize(v)

    # Inputs:
        - Dictionary-like object v with numerical values

    # Outputs:
        - v normalized to have unit L2 norm

    # Depends:
        - math
    """

    len = 0
    for val in v.values():
        len += val * val
    len = math.sqrt(len)
    
    for key, val in v.items():
        v[key] = val / len
    
    return v

# Run file directly from terminal
if __name__ == '__main__':
    # Arguments:
    # "input_filename_part" includes _ at end before numbers
    # "num_in_files": Number of input files
    # "output_filename_part": base of output filename
    if len(sys.argv) != 4:
        print('Expected arguments: input_filename_part num_in_files output_filename_part')
        sys.exit(-1)
        
    # Read in arguments
    input_filename_part = sys.argv[1]
    num_in_files = int(sys.argv[2])
    output_filename_part = sys.argv[3]
    
    # This is a memory saving device.  If true, then nodes' and edges' names will be
    # replaced by an integer.  It may not have saved as much memory as hoped, and is
    # generally kept at False.
    many_repeat_edges = False

    # Un-normalized
    nodevectors = []
    edgevectors = []
    # Normalized for cosine calculation
    nodevectors_norm = []
    edgevectors_norm = []

    # These exist to save on some memory in the vectors ... at present, I'm doing each
    # vector as string --> int and pair of string --> int which likely replicates these
    # values a lot and wastes a considerable amount of memory.  See many_repeat_edges.
    node_to_int_map = {}
    edge_to_int_map = {}

    for file_id in range(num_in_files):
        num_lines = 0
        in_filename = input_filename_part + str(file_id) + '.csv'

        # Read in network (node, edge counts)
        first_line = True
        in_file = open(in_filename, 'r')
        nodev = {}
        edgev = {}
        for line in in_file:
            if first_line:
                if line != 'node_a,node_b,first_time,last_time,num_times\n':
                    print('Expected a file (' + in_filename + ') generated by CreateGraphs.py, but first line didn\'t match: ' + line)
                    sys.exit(-1)
                first_line = False
                continue

            # Ensure file is properly formatted on each line.
            vals = line.split(',')
            if len(vals) == 0:
                continue
            if len(vals) != 5:
                print('Found an improperly formatted line: ' + line)
            cnt = int(vals[4])

            # Always map nodes to integer ids.
            if vals[0] not in node_to_int_map.keys():
                node_to_int_map[vals[0]] = len(node_to_int_map)
            if vals[1] not in node_to_int_map.keys():
                node_to_int_map[vals[1]] = len(node_to_int_map)
            if node_to_int_map[vals[0]] not in nodev.keys():
                nodev[node_to_int_map[vals[0]]] = 0
            if node_to_int_map[vals[1]] not in nodev.keys():
                nodev[node_to_int_map[vals[1]]] = 0
            nodev[node_to_int_map[vals[0]]] += cnt
            nodev[node_to_int_map[vals[1]]] += cnt

            key = (vals[0], vals[1])
            if many_repeat_edges:
                if key not in edge_to_int_map.keys():
                    edge_to_int_map[key] = len(edge_to_int_map)
                if edge_to_int_map[key] not in edgev.keys():
                    edgev[edge_to_int_map[key]] = 0
                if vals[0] != vals[1] and (vals[1], vals[0]) in edge_to_int_map.keys():
                    print('ERROR: Found edge in both orders: ' + str((vals[0], vals[1])))
                    sys.exit()
                key = edge_to_int_map[key]
            else:
                if key not in edgev.keys():
                    edgev[key] = 0
                if vals[0] != vals[1] and (vals[1], vals[0]) in edgev.keys():
                    print('ERROR: Found edge in both orders: ' + str((vals[0], vals[1])))
                    sys.exit()
            edgev[key] += cnt
            num_lines += 1

        in_file.close()

        nodevectors.append(deepcopy(nodev))
        edgevectors.append(deepcopy(edgev))
        nodevectors_norm.append(normalize(nodev))
        edgevectors_norm.append(normalize(edgev))

        print('Completed file %d, pass 1, %d nodes, %d edges total' % (file_id, len(node_to_int_map), len(edge_to_int_map)))

    # Compute and write similarity matrix of networks to file
    # block_size limits how far neighboring snapshots are considered.  This is to save on
    # compute time for running this on datasets with far too many snapshots.
    block_size = 1000
    similarity_out = open(output_filename_part + '.similarity.csv', 'w')
    similarity_out.write('id_x,id_y,nodes_jaccard,edges_jaccard,nodes_cosine,edges_cosine,nodes_wjaccard,edges_wjaccard\n')

    for i in range(num_in_files):
        similarity_out.write('%d,%d,%lf,%lf,%lf,%lf,%lf,%lf\n' % (i, i, 1, 1, 1, 1, 1, 1))
        nset_i = set(nodevectors[i].keys())
        eset_i = set(edgevectors[i].keys())
        for j in range(i+1, min(i+block_size, num_in_files)):

            nset_j = set(nodevectors[j].keys())
            n_union = nset_i.union(nset_j)
            n_intersection = nset_i.intersection(nset_j)
            n_jaccard = len(n_intersection) / len(n_union)

            eset_j = set(edgevectors[j].keys())
            e_union = eset_i.union(eset_j)
            e_intersection = eset_i.intersection(eset_j)
            e_jaccard = len(e_intersection) / len(e_union)

            e_cosine = 0
            for key in e_intersection:
                e_cosine += edgevectors_norm[i][key] * edgevectors_norm[j][key]

            n_cosine = 0
            for key in n_intersection:
                n_cosine += nodevectors_norm[i][key] * nodevectors_norm[j][key]

            num = 0
            den = 0
            for key in e_union:
                if key in edgevectors[i]:
                    l_val = edgevectors[i][key]
                else:
                    l_val = 0
                if key in edgevectors[j]:
                    r_val = edgevectors[j][key]
                else:
                    r_val = 0
                num += min(l_val, r_val)
                den += max(l_val, r_val)
            e_wjaccard = num / den

            num = 0
            den = 0
            for key in n_union:
                if key in nodevectors[i]:
                    l_val = nodevectors[i][key]
                else:
                    l_val = 0
                if key in nodevectors[j]:
                    r_val = nodevectors[j][key]
                else:
                    r_val = 0
                num += min(l_val, r_val)
                den += max(l_val, r_val)
            n_wjaccard = num / den

            similarity_out.write('%d,%d,%lf,%lf,%lf,%lf,%lf,%lf\n' % (i, j, n_jaccard, e_jaccard, n_cosine, e_cosine, n_wjaccard, e_wjaccard))
            similarity_out.write('%d,%d,%lf,%lf,%lf,%lf,%lf,%lf\n' % (j, i, n_jaccard, e_jaccard, n_cosine, e_cosine, n_wjaccard, e_wjaccard))
        nodevectors[i] = None
        edgevectors[i] = None
        print('Completed file %d, pass 2' % (i))
    similarity_out.close()


